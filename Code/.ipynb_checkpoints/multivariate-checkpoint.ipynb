{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca3a321-772f-41df-a6d6-c168918e127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87690055-2533-484b-bd6d-fbf3f3acd1c7",
   "metadata": {},
   "source": [
    "### 1. Import and Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d5a8bb-26eb-4a61-a369-65d076d8963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_mask</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>set_126</th>\n",
       "      <th>historical_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>['12', '11']</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>['12', '1', '7', '13', '8', '3', '4', '11', '6']</td>\n",
       "      <td>['sku2', 'sku4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>['13', '4']</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>['13', '3', '6']</td>\n",
       "      <td>['sku6', 'sku7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>['8', '13', '1']</td>\n",
       "      <td>['sku6', 'sku7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307732</th>\n",
       "      <td>307732</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>['12', '1', '5', '13', '8']</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307733</th>\n",
       "      <td>307733</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>['12', '1', '15', '5', '7', '8', '3', '4', '6'...</td>\n",
       "      <td>['sku3', 'sku5']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307734</th>\n",
       "      <td>307734</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>['12', '1', '14', '10', '8', '3', '9', '11', '6']</td>\n",
       "      <td>['sku2', 'sku4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307735</th>\n",
       "      <td>307735</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>['12', '1', '15', '13', '7', '14', '2', '4', '...</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307736</th>\n",
       "      <td>307736</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>['12', '15', '5', '7', '10', '8', '3', '2', '4...</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307737 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_mask  age  city  gender  \\\n",
       "0             0    4     5       0   \n",
       "1             1    2    62       1   \n",
       "2             2    3   385       0   \n",
       "3             3    4   163       1   \n",
       "4             4    2   229       0   \n",
       "...         ...  ...   ...     ...   \n",
       "307732   307732    3   258       1   \n",
       "307733   307733    8   115       1   \n",
       "307734   307734    3    34       0   \n",
       "307735   307735    3   378       0   \n",
       "307736   307736    3   250       0   \n",
       "\n",
       "                                                  set_126    historical_buy  \n",
       "0                                            ['12', '11']  ['sku8', 'sku2']  \n",
       "1        ['12', '1', '7', '13', '8', '3', '4', '11', '6']  ['sku2', 'sku4']  \n",
       "2                                             ['13', '4']  ['sku8', 'sku2']  \n",
       "3                                        ['13', '3', '6']  ['sku6', 'sku7']  \n",
       "4                                        ['8', '13', '1']  ['sku6', 'sku7']  \n",
       "...                                                   ...               ...  \n",
       "307732                        ['12', '1', '5', '13', '8']  ['sku8', 'sku2']  \n",
       "307733  ['12', '1', '15', '5', '7', '8', '3', '4', '6'...  ['sku3', 'sku5']  \n",
       "307734  ['12', '1', '14', '10', '8', '3', '9', '11', '6']  ['sku2', 'sku4']  \n",
       "307735  ['12', '1', '15', '13', '7', '14', '2', '4', '...  ['sku8', 'sku2']  \n",
       "307736  ['12', '15', '5', '7', '10', '8', '3', '2', '4...  ['sku8', 'sku2']  \n",
       "\n",
       "[307737 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('/Users/xuzhuxuan/Desktop/Intern/Data/media_tag.xlsx')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa7a105-fa12-4c50-a94a-5245c4d0211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    string = row['set_126'].replace('[', '').replace(']', '').replace(\"'\", '')\n",
    "    lst1 = [int(s) for s in string.split(',')]\n",
    "    lst2 = []\n",
    "    for i in range(1,16):\n",
    "        if i in lst1:\n",
    "            lst2.append(1)\n",
    "        else:\n",
    "            lst2.append(0)\n",
    "    return lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfaae608-9973-4f71-94ff-1c8e110ef3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_mask</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>set_126</th>\n",
       "      <th>historical_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>['sku2', 'sku4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>['sku6', 'sku7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>['sku6', 'sku7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307732</th>\n",
       "      <td>307732</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307733</th>\n",
       "      <td>307733</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1]</td>\n",
       "      <td>['sku3', 'sku5']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307734</th>\n",
       "      <td>307734</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0]</td>\n",
       "      <td>['sku2', 'sku4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307735</th>\n",
       "      <td>307735</td>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1]</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307736</th>\n",
       "      <td>307736</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1]</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307737 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_mask  age  city  gender  \\\n",
       "0             0    4     5       0   \n",
       "1             1    2    62       1   \n",
       "2             2    3   385       0   \n",
       "3             3    4   163       1   \n",
       "4             4    2   229       0   \n",
       "...         ...  ...   ...     ...   \n",
       "307732   307732    3   258       1   \n",
       "307733   307733    8   115       1   \n",
       "307734   307734    3    34       0   \n",
       "307735   307735    3   378       0   \n",
       "307736   307736    3   250       0   \n",
       "\n",
       "                                              set_126    historical_buy  \n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]  ['sku8', 'sku2']  \n",
       "1       [1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0]  ['sku2', 'sku4']  \n",
       "2       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  ['sku8', 'sku2']  \n",
       "3       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]  ['sku6', 'sku7']  \n",
       "4       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]  ['sku6', 'sku7']  \n",
       "...                                               ...               ...  \n",
       "307732  [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]  ['sku8', 'sku2']  \n",
       "307733  [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1]  ['sku3', 'sku5']  \n",
       "307734  [1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0]  ['sku2', 'sku4']  \n",
       "307735  [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1]  ['sku8', 'sku2']  \n",
       "307736  [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1]  ['sku8', 'sku2']  \n",
       "\n",
       "[307737 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['set_126'] = df1.apply(clean, axis = 1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368abcf9-e21b-479d-b60c-c5101701c7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set_1</th>\n",
       "      <th>set_2</th>\n",
       "      <th>set_3</th>\n",
       "      <th>set_4</th>\n",
       "      <th>set_5</th>\n",
       "      <th>set_6</th>\n",
       "      <th>set_7</th>\n",
       "      <th>set_8</th>\n",
       "      <th>set_9</th>\n",
       "      <th>set_10</th>\n",
       "      <th>set_11</th>\n",
       "      <th>set_12</th>\n",
       "      <th>set_13</th>\n",
       "      <th>set_14</th>\n",
       "      <th>set_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307732</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307733</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307734</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307735</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307736</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307737 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        set_1  set_2  set_3  set_4  set_5  set_6  set_7  set_8  set_9  set_10  \\\n",
       "0           0      0      0      0      0      0      0      0      0       0   \n",
       "1           1      0      1      1      0      1      1      1      0       0   \n",
       "2           0      0      0      1      0      0      0      0      0       0   \n",
       "3           0      0      1      0      0      1      0      0      0       0   \n",
       "4           1      0      0      0      0      0      0      1      0       0   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "307732      1      0      0      0      1      0      0      1      0       0   \n",
       "307733      1      0      1      1      1      1      1      1      0       0   \n",
       "307734      1      0      1      0      0      1      0      1      1       1   \n",
       "307735      1      1      0      1      0      1      1      0      1       0   \n",
       "307736      0      1      1      1      1      1      1      1      0       1   \n",
       "\n",
       "        set_11  set_12  set_13  set_14  set_15  \n",
       "0            1       1       0       0       0  \n",
       "1            1       1       1       0       0  \n",
       "2            0       0       1       0       0  \n",
       "3            0       0       1       0       0  \n",
       "4            0       0       1       0       0  \n",
       "...        ...     ...     ...     ...     ...  \n",
       "307732       0       1       1       0       0  \n",
       "307733       1       1       0       0       1  \n",
       "307734       1       1       0       1       0  \n",
       "307735       0       1       1       1       1  \n",
       "307736       0       1       0       0       1  \n",
       "\n",
       "[307737 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df1['set_126'].values.tolist(),columns = ['set_1','set_2','set_3','set_4','set_5','set_6','set_7','set_8','set_9','set_10','set_11','set_12','set_13','set_14','set_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99c8a25d-0988-4bd1-b2be-e39c06f12883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>set_1</th>\n",
       "      <th>set_2</th>\n",
       "      <th>set_3</th>\n",
       "      <th>set_4</th>\n",
       "      <th>set_5</th>\n",
       "      <th>set_6</th>\n",
       "      <th>set_7</th>\n",
       "      <th>set_8</th>\n",
       "      <th>set_9</th>\n",
       "      <th>set_10</th>\n",
       "      <th>set_11</th>\n",
       "      <th>set_12</th>\n",
       "      <th>set_13</th>\n",
       "      <th>set_14</th>\n",
       "      <th>set_15</th>\n",
       "      <th>historical_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku2', 'sku4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku6', 'sku7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku6', 'sku7']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307732</th>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307733</th>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['sku3', 'sku5']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307734</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['sku2', 'sku4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307735</th>\n",
       "      <td>3</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307736</th>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['sku8', 'sku2']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307737 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  city  gender  set_1  set_2  set_3  set_4  set_5  set_6  set_7  \\\n",
       "0         4     5       0      0      0      0      0      0      0      0   \n",
       "1         2    62       1      1      0      1      1      0      1      1   \n",
       "2         3   385       0      0      0      0      1      0      0      0   \n",
       "3         4   163       1      0      0      1      0      0      1      0   \n",
       "4         2   229       0      1      0      0      0      0      0      0   \n",
       "...     ...   ...     ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "307732    3   258       1      1      0      0      0      1      0      0   \n",
       "307733    8   115       1      1      0      1      1      1      1      1   \n",
       "307734    3    34       0      1      0      1      0      0      1      0   \n",
       "307735    3   378       0      1      1      0      1      0      1      1   \n",
       "307736    3   250       0      0      1      1      1      1      1      1   \n",
       "\n",
       "        set_8  set_9  set_10  set_11  set_12  set_13  set_14  set_15  \\\n",
       "0           0      0       0       1       1       0       0       0   \n",
       "1           1      0       0       1       1       1       0       0   \n",
       "2           0      0       0       0       0       1       0       0   \n",
       "3           0      0       0       0       0       1       0       0   \n",
       "4           1      0       0       0       0       1       0       0   \n",
       "...       ...    ...     ...     ...     ...     ...     ...     ...   \n",
       "307732      1      0       0       0       1       1       0       0   \n",
       "307733      1      0       0       1       1       0       0       1   \n",
       "307734      1      1       1       1       1       0       1       0   \n",
       "307735      0      1       0       0       1       1       1       1   \n",
       "307736      1      0       1       0       1       0       0       1   \n",
       "\n",
       "          historical_buy  \n",
       "0       ['sku8', 'sku2']  \n",
       "1       ['sku2', 'sku4']  \n",
       "2       ['sku8', 'sku2']  \n",
       "3       ['sku6', 'sku7']  \n",
       "4       ['sku6', 'sku7']  \n",
       "...                  ...  \n",
       "307732  ['sku8', 'sku2']  \n",
       "307733  ['sku3', 'sku5']  \n",
       "307734  ['sku2', 'sku4']  \n",
       "307735  ['sku8', 'sku2']  \n",
       "307736  ['sku8', 'sku2']  \n",
       "\n",
       "[307737 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([df1[['age','city','gender']],pd.DataFrame(df1['set_126'].values.tolist(),columns = ['set_1','set_2','set_3','set_4','set_5','set_6','set_7','set_8','set_9','set_10','set_11','set_12','set_13','set_14','set_15']),df1['historical_buy']], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1ca0a-5316-42d3-9f13-f38ceea2a7ae",
   "metadata": {},
   "source": [
    "### 2. Define X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ae1dc7-7581-4bf7-bebe-951d8b763c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df2.values\n",
    "\n",
    "X = dataset[:,0:18].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e6caeb-3615-4bdd-af86-600aea1cbde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sku8', 'sku2']    92321\n",
       "['sku2', 'sku4']    64145\n",
       "['sku8', 'sku7']    48344\n",
       "['sku6', 'sku7']    39099\n",
       "['sku1', 'sku8']    38867\n",
       "['sku3', 'sku5']    24961\n",
       "Name: historical_buy, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['historical_buy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4c041c-e3cf-4df5-b3fa-661fa8408ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 4 ... 1 4 4]\n",
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y = df2['historical_buy']\n",
    "\n",
    "# work with labels\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "print(encoded_Y)\n",
    "print(dummy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1b7b2-4cf2-4d56-94d3-a1c70358f523",
   "metadata": {},
   "source": [
    "### 3. Define and Train Model (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466a7da6-a544-40d5-9ffc-6b9c2292c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 09:55:36.668222: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=18, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3afe5fa8-9639-4146-8f89-a6ec26a0964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1924/1924 [==============================] - 4s 1ms/step - loss: 1.2755 - accuracy: 0.4537 - val_loss: 0.8603 - val_accuracy: 0.5625\n",
      "Epoch 2/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.7919 - accuracy: 0.5977 - val_loss: 0.7402 - val_accuracy: 0.6532\n",
      "Epoch 3/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.7211 - accuracy: 0.6456 - val_loss: 0.6937 - val_accuracy: 0.6683\n",
      "Epoch 4/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.7002 - accuracy: 0.6538 - val_loss: 0.6786 - val_accuracy: 0.6624\n",
      "Epoch 5/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6931 - accuracy: 0.6565 - val_loss: 0.6786 - val_accuracy: 0.6661\n",
      "Epoch 6/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6854 - accuracy: 0.6626 - val_loss: 0.6753 - val_accuracy: 0.6692\n",
      "Epoch 7/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6816 - accuracy: 0.6647 - val_loss: 0.6617 - val_accuracy: 0.6707\n",
      "Epoch 8/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6762 - accuracy: 0.6672 - val_loss: 0.7211 - val_accuracy: 0.6524\n",
      "Epoch 9/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6747 - accuracy: 0.6676 - val_loss: 0.6573 - val_accuracy: 0.6751\n",
      "Epoch 10/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6717 - accuracy: 0.6684 - val_loss: 0.6585 - val_accuracy: 0.6799\n",
      "Epoch 11/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6726 - accuracy: 0.6685 - val_loss: 0.6617 - val_accuracy: 0.6784\n",
      "Epoch 12/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6679 - accuracy: 0.6700 - val_loss: 0.6675 - val_accuracy: 0.6670\n",
      "Epoch 13/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6707 - accuracy: 0.6698 - val_loss: 0.7105 - val_accuracy: 0.6549\n",
      "Epoch 14/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6681 - accuracy: 0.6701 - val_loss: 0.6578 - val_accuracy: 0.6732\n",
      "Epoch 15/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6638 - accuracy: 0.6712 - val_loss: 0.6503 - val_accuracy: 0.6801\n",
      "Epoch 16/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6647 - accuracy: 0.6713 - val_loss: 0.6537 - val_accuracy: 0.6795\n",
      "Epoch 17/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6665 - accuracy: 0.6704 - val_loss: 0.6546 - val_accuracy: 0.6805\n",
      "Epoch 18/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6635 - accuracy: 0.6720 - val_loss: 0.6671 - val_accuracy: 0.6766\n",
      "Epoch 19/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6601 - accuracy: 0.6730 - val_loss: 0.6545 - val_accuracy: 0.6705\n",
      "Epoch 20/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6593 - accuracy: 0.6736 - val_loss: 0.6895 - val_accuracy: 0.6635\n",
      "Epoch 21/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6612 - accuracy: 0.6729 - val_loss: 0.6489 - val_accuracy: 0.6745\n",
      "Epoch 22/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6603 - accuracy: 0.6731 - val_loss: 0.6511 - val_accuracy: 0.6833\n",
      "Epoch 23/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6607 - accuracy: 0.6732 - val_loss: 0.6599 - val_accuracy: 0.6699\n",
      "Epoch 24/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6594 - accuracy: 0.6736 - val_loss: 0.6712 - val_accuracy: 0.6668\n",
      "Epoch 25/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6591 - accuracy: 0.6738 - val_loss: 0.6460 - val_accuracy: 0.6820\n",
      "Epoch 26/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6597 - accuracy: 0.6735 - val_loss: 0.6547 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6571 - accuracy: 0.6746 - val_loss: 0.6684 - val_accuracy: 0.6820\n",
      "Epoch 28/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6573 - accuracy: 0.6749 - val_loss: 0.6505 - val_accuracy: 0.6750\n",
      "Epoch 29/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6564 - accuracy: 0.6748 - val_loss: 0.6482 - val_accuracy: 0.6787\n",
      "Epoch 30/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6560 - accuracy: 0.6754 - val_loss: 0.6497 - val_accuracy: 0.6916\n",
      "Epoch 31/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6556 - accuracy: 0.6759 - val_loss: 0.6452 - val_accuracy: 0.6852\n",
      "Epoch 32/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6558 - accuracy: 0.6759 - val_loss: 0.6582 - val_accuracy: 0.6859\n",
      "Epoch 33/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6565 - accuracy: 0.6763 - val_loss: 0.6481 - val_accuracy: 0.6805\n",
      "Epoch 34/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6533 - accuracy: 0.6773 - val_loss: 0.6800 - val_accuracy: 0.6656\n",
      "Epoch 35/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6528 - accuracy: 0.6778 - val_loss: 0.6420 - val_accuracy: 0.6829\n",
      "Epoch 36/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6517 - accuracy: 0.6786 - val_loss: 0.6545 - val_accuracy: 0.6747\n",
      "Epoch 37/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6519 - accuracy: 0.6788 - val_loss: 0.6624 - val_accuracy: 0.6735\n",
      "Epoch 38/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6514 - accuracy: 0.6796 - val_loss: 0.6402 - val_accuracy: 0.6814\n",
      "Epoch 39/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6556 - accuracy: 0.6777 - val_loss: 0.6403 - val_accuracy: 0.6868\n",
      "Epoch 40/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6510 - accuracy: 0.6799 - val_loss: 0.6414 - val_accuracy: 0.6930\n",
      "Epoch 41/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6507 - accuracy: 0.6811 - val_loss: 0.6376 - val_accuracy: 0.6926\n",
      "Epoch 42/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6498 - accuracy: 0.6812 - val_loss: 0.6727 - val_accuracy: 0.6738\n",
      "Epoch 43/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6490 - accuracy: 0.6816 - val_loss: 0.6408 - val_accuracy: 0.6818\n",
      "Epoch 44/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6524 - accuracy: 0.6812 - val_loss: 0.6414 - val_accuracy: 0.6914\n",
      "Epoch 45/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6496 - accuracy: 0.6820 - val_loss: 0.6389 - val_accuracy: 0.6942\n",
      "Epoch 46/300\n",
      "1924/1924 [==============================] - 4s 2ms/step - loss: 0.6484 - accuracy: 0.6832 - val_loss: 0.6426 - val_accuracy: 0.6916\n",
      "Epoch 47/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6470 - accuracy: 0.6834 - val_loss: 0.6401 - val_accuracy: 0.6935\n",
      "Epoch 48/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6469 - accuracy: 0.6843 - val_loss: 0.6510 - val_accuracy: 0.6776\n",
      "Epoch 49/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6498 - accuracy: 0.6835 - val_loss: 0.6385 - val_accuracy: 0.6855\n",
      "Epoch 50/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6466 - accuracy: 0.6847 - val_loss: 0.6344 - val_accuracy: 0.6947\n",
      "Epoch 51/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6465 - accuracy: 0.6849 - val_loss: 0.6383 - val_accuracy: 0.6927\n",
      "Epoch 52/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6459 - accuracy: 0.6847 - val_loss: 0.6495 - val_accuracy: 0.6899\n",
      "Epoch 53/300\n",
      "1924/1924 [==============================] - 5s 3ms/step - loss: 0.6467 - accuracy: 0.6847 - val_loss: 0.6826 - val_accuracy: 0.6649\n",
      "Epoch 54/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6454 - accuracy: 0.6858 - val_loss: 0.6340 - val_accuracy: 0.6943\n",
      "Epoch 55/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6447 - accuracy: 0.6865 - val_loss: 0.6381 - val_accuracy: 0.6895\n",
      "Epoch 56/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6434 - accuracy: 0.6869 - val_loss: 0.6393 - val_accuracy: 0.6904\n",
      "Epoch 57/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6448 - accuracy: 0.6868 - val_loss: 0.6359 - val_accuracy: 0.6855\n",
      "Epoch 58/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6455 - accuracy: 0.6863 - val_loss: 0.6550 - val_accuracy: 0.6927\n",
      "Epoch 59/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6435 - accuracy: 0.6875 - val_loss: 0.6433 - val_accuracy: 0.6886\n",
      "Epoch 60/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6430 - accuracy: 0.6878 - val_loss: 0.6353 - val_accuracy: 0.6971\n",
      "Epoch 61/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6450 - accuracy: 0.6868 - val_loss: 0.6391 - val_accuracy: 0.6914\n",
      "Epoch 62/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6434 - accuracy: 0.6874 - val_loss: 0.6453 - val_accuracy: 0.6884\n",
      "Epoch 63/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6412 - accuracy: 0.6885 - val_loss: 0.6406 - val_accuracy: 0.6928\n",
      "Epoch 64/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6411 - accuracy: 0.6884 - val_loss: 0.6482 - val_accuracy: 0.6874\n",
      "Epoch 65/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6405 - accuracy: 0.6889 - val_loss: 0.6400 - val_accuracy: 0.6849\n",
      "Epoch 66/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6423 - accuracy: 0.6884 - val_loss: 0.6448 - val_accuracy: 0.6927\n",
      "Epoch 67/300\n",
      "1924/1924 [==============================] - 4s 2ms/step - loss: 0.6427 - accuracy: 0.6883 - val_loss: 0.6333 - val_accuracy: 0.6906\n",
      "Epoch 68/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6400 - accuracy: 0.6895 - val_loss: 0.6472 - val_accuracy: 0.6882\n",
      "Epoch 69/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6401 - accuracy: 0.6894 - val_loss: 0.6556 - val_accuracy: 0.6849\n",
      "Epoch 70/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6401 - accuracy: 0.6892 - val_loss: 0.6546 - val_accuracy: 0.6859\n",
      "Epoch 71/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6428 - accuracy: 0.6884 - val_loss: 0.6341 - val_accuracy: 0.6949\n",
      "Epoch 72/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6393 - accuracy: 0.6903 - val_loss: 0.6483 - val_accuracy: 0.6822\n",
      "Epoch 73/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6392 - accuracy: 0.6899 - val_loss: 0.6331 - val_accuracy: 0.6939\n",
      "Epoch 74/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6387 - accuracy: 0.6897 - val_loss: 0.6314 - val_accuracy: 0.6933\n",
      "Epoch 75/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6381 - accuracy: 0.6901 - val_loss: 0.6307 - val_accuracy: 0.6953\n",
      "Epoch 76/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6394 - accuracy: 0.6899 - val_loss: 0.6367 - val_accuracy: 0.6951\n",
      "Epoch 77/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6413 - accuracy: 0.6889 - val_loss: 0.6332 - val_accuracy: 0.6939\n",
      "Epoch 78/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6395 - accuracy: 0.6896 - val_loss: 0.6325 - val_accuracy: 0.6946\n",
      "Epoch 79/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6373 - accuracy: 0.6907 - val_loss: 0.6425 - val_accuracy: 0.6905\n",
      "Epoch 80/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6365 - accuracy: 0.6909 - val_loss: 0.6400 - val_accuracy: 0.6911\n",
      "Epoch 81/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6370 - accuracy: 0.6907 - val_loss: 0.6401 - val_accuracy: 0.6899\n",
      "Epoch 82/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6357 - accuracy: 0.6913 - val_loss: 0.6386 - val_accuracy: 0.6948\n",
      "Epoch 83/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6363 - accuracy: 0.6909 - val_loss: 0.6348 - val_accuracy: 0.6959\n",
      "Epoch 84/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6365 - accuracy: 0.6910 - val_loss: 0.6463 - val_accuracy: 0.6932\n",
      "Epoch 85/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6363 - accuracy: 0.6910 - val_loss: 0.6298 - val_accuracy: 0.6942\n",
      "Epoch 86/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6364 - accuracy: 0.6911 - val_loss: 0.6351 - val_accuracy: 0.6941\n",
      "Epoch 87/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6359 - accuracy: 0.6912 - val_loss: 0.6312 - val_accuracy: 0.6950\n",
      "Epoch 88/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6361 - accuracy: 0.6912 - val_loss: 0.6534 - val_accuracy: 0.6872\n",
      "Epoch 89/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6363 - accuracy: 0.6911 - val_loss: 0.6327 - val_accuracy: 0.6979\n",
      "Epoch 90/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6345 - accuracy: 0.6916 - val_loss: 0.6311 - val_accuracy: 0.6944\n",
      "Epoch 91/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6354 - accuracy: 0.6909 - val_loss: 0.6456 - val_accuracy: 0.6889\n",
      "Epoch 92/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6348 - accuracy: 0.6911 - val_loss: 0.7224 - val_accuracy: 0.6532\n",
      "Epoch 93/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6354 - accuracy: 0.6914 - val_loss: 0.6307 - val_accuracy: 0.6944\n",
      "Epoch 94/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6340 - accuracy: 0.6915 - val_loss: 0.6415 - val_accuracy: 0.6836\n",
      "Epoch 95/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6340 - accuracy: 0.6916 - val_loss: 0.6366 - val_accuracy: 0.6960\n",
      "Epoch 96/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6342 - accuracy: 0.6916 - val_loss: 0.6293 - val_accuracy: 0.6926\n",
      "Epoch 97/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6335 - accuracy: 0.6919 - val_loss: 0.6308 - val_accuracy: 0.6957\n",
      "Epoch 98/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6341 - accuracy: 0.6917 - val_loss: 0.6301 - val_accuracy: 0.6942\n",
      "Epoch 99/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6338 - accuracy: 0.6917 - val_loss: 0.6287 - val_accuracy: 0.6935\n",
      "Epoch 100/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6350 - accuracy: 0.6913 - val_loss: 0.6311 - val_accuracy: 0.6901\n",
      "Epoch 101/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6322 - accuracy: 0.6924 - val_loss: 0.6303 - val_accuracy: 0.6953\n",
      "Epoch 102/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6361 - accuracy: 0.6905 - val_loss: 0.6391 - val_accuracy: 0.6952\n",
      "Epoch 103/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6330 - accuracy: 0.6917 - val_loss: 0.6412 - val_accuracy: 0.6931\n",
      "Epoch 104/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6337 - accuracy: 0.6914 - val_loss: 0.6337 - val_accuracy: 0.6981\n",
      "Epoch 105/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6327 - accuracy: 0.6919 - val_loss: 0.6348 - val_accuracy: 0.6904\n",
      "Epoch 106/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6331 - accuracy: 0.6917 - val_loss: 0.6875 - val_accuracy: 0.6589\n",
      "Epoch 107/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6342 - accuracy: 0.6912 - val_loss: 0.6300 - val_accuracy: 0.6910\n",
      "Epoch 108/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6332 - accuracy: 0.6921 - val_loss: 0.6310 - val_accuracy: 0.6976\n",
      "Epoch 109/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6328 - accuracy: 0.6916 - val_loss: 0.6279 - val_accuracy: 0.6932\n",
      "Epoch 110/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6327 - accuracy: 0.6917 - val_loss: 0.6353 - val_accuracy: 0.6966\n",
      "Epoch 111/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6344 - accuracy: 0.6913 - val_loss: 0.6372 - val_accuracy: 0.6936\n",
      "Epoch 112/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6317 - accuracy: 0.6926 - val_loss: 0.6314 - val_accuracy: 0.6926\n",
      "Epoch 113/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6334 - accuracy: 0.6916 - val_loss: 0.6414 - val_accuracy: 0.6901\n",
      "Epoch 114/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6327 - accuracy: 0.6920 - val_loss: 0.6486 - val_accuracy: 0.6733\n",
      "Epoch 115/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6314 - accuracy: 0.6926 - val_loss: 0.6309 - val_accuracy: 0.6945\n",
      "Epoch 116/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6328 - accuracy: 0.6921 - val_loss: 0.6301 - val_accuracy: 0.6985\n",
      "Epoch 117/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6326 - accuracy: 0.6918 - val_loss: 0.6292 - val_accuracy: 0.6976\n",
      "Epoch 118/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6321 - accuracy: 0.6924 - val_loss: 0.6341 - val_accuracy: 0.6908\n",
      "Epoch 119/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6333 - accuracy: 0.6916 - val_loss: 0.6323 - val_accuracy: 0.6873\n",
      "Epoch 120/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6319 - accuracy: 0.6922 - val_loss: 0.6725 - val_accuracy: 0.6663\n",
      "Epoch 121/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6318 - accuracy: 0.6919 - val_loss: 0.6279 - val_accuracy: 0.6968\n",
      "Epoch 122/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6308 - accuracy: 0.6926 - val_loss: 0.6356 - val_accuracy: 0.6968\n",
      "Epoch 123/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6317 - accuracy: 0.6920 - val_loss: 0.6280 - val_accuracy: 0.6970\n",
      "Epoch 124/300\n",
      "1924/1924 [==============================] - 2s 1ms/step - loss: 0.6325 - accuracy: 0.6918 - val_loss: 0.6286 - val_accuracy: 0.6969\n",
      "Epoch 125/300\n",
      "1924/1924 [==============================] - 4s 2ms/step - loss: 0.6316 - accuracy: 0.6923 - val_loss: 0.6334 - val_accuracy: 0.6980\n",
      "Epoch 126/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6316 - accuracy: 0.6924 - val_loss: 0.6283 - val_accuracy: 0.6968\n",
      "Epoch 127/300\n",
      "1924/1924 [==============================] - 3s 1ms/step - loss: 0.6324 - accuracy: 0.6920 - val_loss: 0.6351 - val_accuracy: 0.6927\n",
      "Epoch 128/300\n",
      "1924/1924 [==============================] - 3s 2ms/step - loss: 0.6359 - accuracy: 0.6912 - val_loss: 0.6335 - val_accuracy: 0.6954\n",
      "Epoch 129/300\n",
      "1924/1924 [==============================] - 5s 2ms/step - loss: 0.6296 - accuracy: 0.6930 - val_loss: 0.6577 - val_accuracy: 0.6775\n"
     ]
    }
   ],
   "source": [
    "# early stopping callback:this callback will stop the training when there is no improvement in \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min',\n",
    "                                   patience=20, \n",
    "                                   restore_best_weights=True) \n",
    "\n",
    "# now we just update our model fit call\n",
    "history = model.fit(X,\n",
    "                    dummy_y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=300, \n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a9a682-3390-4207-834c-3c7cc845fa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "# learning curve\n",
    "# accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"r\" is for \"solid red line\"\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8534bf-fdaf-4c84-a236-1699aea98ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef2090-1cb0-4661-93ed-8069a9a2698d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8618a4e-18b4-4225-bbf0-f9c86e3b6519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5159e-bf32-4e4c-b7ad-335a7b5055da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35326cca-8211-435c-8168-c807968b37a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de94cb9a-3ddb-4e8e-9ed5-757dbf3241af",
   "metadata": {},
   "source": [
    "### 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae26944-de46-4d5e-836f-bd7cda05de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdffa78b-f4ac-42c8-8879-d44a9edae525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 80% of data into training and 20% into validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f0cb844-d391-482c-a5b9-36d91e3cccf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='mlogloss', gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor=None, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
    "              gamma=0, gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.2,\n",
    "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
    "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e840acb-6814-4640-93d9-3d0254be5f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6989504126860336"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d12d43-ca06-4a2e-ad11-21ebddc5e7c4",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4cf588-7f3e-4883-91df-ddf2c808210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ba80be-281b-45cb-98f1-1f9a696f2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_acc(eta, gamma, max_depth):\n",
    "    xgb = XGBClassifier(learning_rate=max(eta, 0),\n",
    "                       gamma=max(gamma, 0),\n",
    "                       max_depth=int(max_depth),                                               \n",
    "              base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
    "              gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', \n",
    "              max_delta_step=0, min_child_weight=1, missing=nan,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
    "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None\n",
    "                )\n",
    "    xgb.fit(X_train,y_train)\n",
    "    y_pred=xgb.predict(X_test)\n",
    "    val = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe2c4138-10db-4ee9-b908-e0c013ca8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(\n",
    "    xgb_acc,\n",
    "    {\"eta\": (0.001, 0.4),\n",
    "    \"gamma\": (0, 20),\n",
    "    \"max_depth\": (1, 2000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb726ec6-6ef6-4aa2-9d25-2abc5d7d89fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    eta    |   gamma   | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6947  \u001b[0m | \u001b[0m 0.3498  \u001b[0m | \u001b[0m 4.444   \u001b[0m | \u001b[0m 827.5   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7007  \u001b[0m | \u001b[95m 0.2237  \u001b[0m | \u001b[95m 5.928   \u001b[0m | \u001b[95m 468.2   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.2157  \u001b[0m | \u001b[0m 9.462   \u001b[0m | \u001b[0m 1.957e+0\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.04237 \u001b[0m | \u001b[0m 14.66   \u001b[0m | \u001b[0m 665.9   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.01117 \u001b[0m | \u001b[0m 14.12   \u001b[0m | \u001b[0m 908.5   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.1588  \u001b[0m | \u001b[0m 7.848   \u001b[0m | \u001b[0m 468.6   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.04072 \u001b[0m | \u001b[0m 19.17   \u001b[0m | \u001b[0m 975.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6472  \u001b[0m | \u001b[0m 0.2136  \u001b[0m | \u001b[0m 0.2408  \u001b[0m | \u001b[0m 384.9   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.637   \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 542.5   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.3224  \u001b[0m | \u001b[0m 11.8    \u001b[0m | \u001b[0m 726.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.008046\u001b[0m | \u001b[0m 16.46   \u001b[0m | \u001b[0m 1.893e+0\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6457  \u001b[0m | \u001b[0m 0.2762  \u001b[0m | \u001b[0m 0.3747  \u001b[0m | \u001b[0m 1.044e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 0.08274 \u001b[0m | \u001b[0m 4.39    \u001b[0m | \u001b[0m 1.831e+0\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.1978  \u001b[0m | \u001b[0m 15.65   \u001b[0m | \u001b[0m 1.766e+0\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 0.2767  \u001b[0m | \u001b[0m 2.978   \u001b[0m | \u001b[0m 1.7e+03 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5795  \u001b[0m | \u001b[0m 0.004518\u001b[0m | \u001b[0m 11.84   \u001b[0m | \u001b[0m 1.364   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.1775  \u001b[0m | \u001b[0m 19.45   \u001b[0m | \u001b[0m 1.402e+0\u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6435  \u001b[0m | \u001b[0m 0.3947  \u001b[0m | \u001b[0m 0.7067  \u001b[0m | \u001b[0m 1.302e+0\u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.492e+0\u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6393  \u001b[0m | \u001b[0m 0.3878  \u001b[0m | \u001b[0m 0.08167 \u001b[0m | \u001b[0m 1.576e+0\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.2466  \u001b[0m | \u001b[0m 19.73   \u001b[0m | \u001b[0m 206.7   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6476  \u001b[0m | \u001b[0m 0.394   \u001b[0m | \u001b[0m 1.333   \u001b[0m | \u001b[0m 143.9   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 268.8   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.698   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.447e+0\u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 1.175e+0\u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.1182  \u001b[0m | \u001b[0m 18.14   \u001b[0m | \u001b[0m 1.999e+0\u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.1187  \u001b[0m | \u001b[0m 19.91   \u001b[0m | \u001b[0m 774.6   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.637   \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 237.8   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6777  \u001b[0m | \u001b[0m 0.1437  \u001b[0m | \u001b[0m 2.02    \u001b[0m | \u001b[0m 943.0   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.698   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.796e+0\u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f800cd5-4594-4653-a50b-fb486416e305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.700705140703191,\n",
       " 'params': {'eta': 0.2237072245385997,\n",
       "  'gamma': 5.927569204796194,\n",
       "  'max_depth': 468.15946770080285}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cafba9-c14b-4841-9f09-4e1da0779bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97170369-a1c8-4af2-8b87-31cb76e93ba3",
   "metadata": {},
   "source": [
    "### 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e70df5fc-d203-4d49-831a-fb5da52f52a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=300)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73d84de8-ee60-4c04-aede-57c3999662b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.657470592058231\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1bdc4-a251-4c40-8e1a-66eaadaac8fd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc6c706-9423-490e-924b-2da5c6ed358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ea6f3fe-aae5-4156-a152-b1b61c2ed4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_acc(n_estimators, min_samples_split, max_features, max_depth):\n",
    "    clf = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "          min_samples_split = int(min_samples_split),\n",
    "          max_features = min(max_features, 0.999),\n",
    "          max_depth=int(max_depth),\n",
    "          random_state=2\n",
    "                )\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    val = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac2cf26b-fd76-499b-a9b4-3ea718bb7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bo = BayesianOptimization(\n",
    "    rf_acc,\n",
    "    {'n_estimators': (100,500),\n",
    "     'min_samples_split': (2,25),\n",
    "     'max_features': (0.1, 0.999),\n",
    "     'max_depth': (5,15)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c7a4e-f975-4966-a29e-fc3292d28e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 5.074   \u001b[0m | \u001b[0m 0.3352  \u001b[0m | \u001b[0m 13.12   \u001b[0m | \u001b[0m 126.3   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7005  \u001b[0m | \u001b[95m 14.8    \u001b[0m | \u001b[95m 0.8043  \u001b[0m | \u001b[95m 12.91   \u001b[0m | \u001b[95m 414.9   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7006  \u001b[0m | \u001b[95m 14.16   \u001b[0m | \u001b[95m 0.7799  \u001b[0m | \u001b[95m 12.04   \u001b[0m | \u001b[95m 338.4   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7007  \u001b[0m | \u001b[95m 6.313   \u001b[0m | \u001b[95m 0.5845  \u001b[0m | \u001b[95m 19.07   \u001b[0m | \u001b[95m 267.6   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 13.44   \u001b[0m | \u001b[0m 0.2943  \u001b[0m | \u001b[0m 15.37   \u001b[0m | \u001b[0m 409.2   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4154  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7003  \u001b[0m | \u001b[0m 14.86   \u001b[0m | \u001b[0m 0.7192  \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 211.7   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4154  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 300.7   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 10.12   \u001b[0m | \u001b[0m 0.6894  \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 240.5   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7003  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 368.7   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4154  \u001b[0m | \u001b[0m 5.773   \u001b[0m | \u001b[0m 0.1401  \u001b[0m | \u001b[0m 24.57   \u001b[0m | \u001b[0m 188.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 5.297   \u001b[0m | \u001b[0m 0.5537  \u001b[0m | \u001b[0m 24.47   \u001b[0m | \u001b[0m 355.8   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4154  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 439.4   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5787  \u001b[0m | \u001b[0m 6.079   \u001b[0m | \u001b[0m 0.3297  \u001b[0m | \u001b[0m 2.157   \u001b[0m | \u001b[0m 388.3   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6998  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 256.8   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.506   \u001b[0m | \u001b[0m 5.925   \u001b[0m | \u001b[0m 0.2368  \u001b[0m | \u001b[0m 2.724   \u001b[0m | \u001b[0m 351.9   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 14.05   \u001b[0m | \u001b[0m 0.8869  \u001b[0m | \u001b[0m 21.61   \u001b[0m | \u001b[0m 255.3   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 378.4   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5088  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 329.1   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6988  \u001b[0m | \u001b[0m 14.58   \u001b[0m | \u001b[0m 0.259   \u001b[0m | \u001b[0m 2.202   \u001b[0m | \u001b[0m 230.8   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7005  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 20.17   \u001b[0m | \u001b[0m 223.2   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "rf_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298ae0d-20f0-47c6-806f-49123a0be10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bo.max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
